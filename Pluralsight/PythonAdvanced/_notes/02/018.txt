Interpreting Binary Structures
The Python standard library struct module is so called because it's capable of decoding the byte pattern of struct objects from the C and C++ languages. Structs, short for structures, are composite data types, which consist of the byte patterns for C language primitives concatenated together. It may not be immediately obvious why this is necessary or even useful in a language like Python, but being very close to the machine level, C data types are something of a low level lingua franca for binary data exchange between programs in many languages. Furthermore, as most operating systems are written in C or C++, the ability to interpret C structures into Python values and back again, takes on even greater significance. In this demo we're going to write a binary file from a C program, read the file from a Python program, create Python classes, which mirror C data structures, and demonstrate diagnostic techniques for dealing with binary data. This isn't a course on C, but we're sure you'll understand the following C structures for vector, color, and vertex in this program written in the C99 variant of the language. As you can see, we declare a vector to be comprised of three float values. At this point, it's important to realize that a C float is actually a single precision floating point value represented with 32-bits, which is different from a Python float, which you'll recall is a double precision floating point value represented with 64 bits. We then declare a color structure, which comprises three, unsigned, short integers. Again, this integer type is quite different from what we have available in Python, where we have arbitrary precision signed integers. In fact, C's unsigned short in can only represent values from 0 through to 65, 535 with only 16-bits of precision. The third structure we declare is a vertex, which combines a vector and a color together into one larger structure. In the main function this program creates an array of four vertex structures and writes them to a file called colors. bin before exiting. We'll now compile the C program into an executable. The details of how you do this are heavily system dependent, and require that you at least have access to a C99 compiler. On our Mac OS X system with the Xcode development tools installed we can simply use make from the command line. Make colorpoints compiles colorpoints. c into an executable called simply, colorpoints. When we run the executable a colors. bin file is produced, as expected. Now we have a binary file. Let's try to make sense of it in Python. Our starting point will be a simple program to read only the first vertex from the file. The program will be called reader. py. In the main function we open the file for read, being careful to remember to do so in binary mode. Then we use the read method of file objects to read the entire contents of the file into a bytes object. We use the struct. unpack_from function to convert the raw byte sequence into more friendly types. This function accepts a special format string containing codes which specify how to interpret the bytes. The leading at character specifies that native byte order and alignment are to be used. Other leading characters can be used to force particular byte orderings, such as less than for little-endian, and greater than for bit-endian. It's also possible to choose between native alignment and no alignment, a topic we'll be revisiting shortly. If no byte order character is specified, then at, the native byte order, is assumed. In our example each of the three f characters tells struct to expect a single precision c float, and each of the upper case H characters tells struct to expect an unsigned short int, which is a 16-bit type. There are also code letters corresponding to all of the common C datatypes, which are mostly variations on different precisions of signed and unsigned integers together with 32 and 64-bit floating point numbers, bytearrays, pointers, and fixed length strings. Running our program, we can see that struct. unpack_from returns a tuple. The reason our values don't look exactly the same way as they did in the source code to our C program is because we specified the values in decimal in the source, and the values we chose are not representable exactly in binary. There has also been a conversion from the single precision C float to the double precision Python float, which is why the values we get back have so many more digits. Of course, the 16-bit unsigned short int values from C can be represented exactly as Python int objects. One obvious improvement to our program, given that unpack_from returns a tuple, is to use tuple unpacking to place the values into named variables. Here we use x, y, z, red, green, and blue. We can also shorten our format strings slightly by using repeat counts. For example, 3f means the same as fff. That's no big win, in this case, but it can be very useful for larger data series. Finally, of course, we'd like to read all four vertex structures from our file. We'll also make the example a bit more realistic by reading the data into Python classes, which are equivalents of the vector, color, and vertex structs we had in C. Each class specifies simple data objects with just a dunder in it to store instance variables and a dunder wrapper to display them. We also make a factory function to construct instances of the type vertex, which aggregates a vector and a color. We'll add an import for pretty printing at the top of the module, and then we'll rework the main function to use struct. iter_unpack, which iterates over binary objects with an identical format specification. When we've accumulated all of the vertices into a list we pretty print the results in data structure. In fact, we can simply unwind one of our earlier refactorings and simply unpack a fields to pull directly into the arguments of make_colored_vertex using extended call syntax. In this code fields will be the tuple of six floating int values returned for each structure. Rather than unpacking into named variables we use extended call syntax to unpack the field's tuple directly into the arguments of make_colored_vertex. Let's try it. Oh dear. What happened? The struct. iter_unpack function is complaining because it expects the buffer byte sequence to be a multiple of 18 bytes long. Each of our structures consist of three 4 byte floats and three 2 byte unsigned short integers; (3*4) + (3*2) is indeed 18, so how long is our buffer? Let's add some temporary diagnostic code to our program. After we read the file we will print the buffer length and the buffer contents. Curiously, the buffer is reporting as containing 80 bytes, and checking at the command line we can see that that's consistent with the file length. We're expecting 4 lots of 18, which is 72 bytes, so where are the extra 8 bytes coming from? Some investigation is required. It's really awkward to read standard bytes representation, especially when it contains a mix of printable ASCII characters and escape sequences. We can't directly convert a binary sequence into a readable hex string, but Python 3 has some tools in the standard library to help in the form of the bin ASCII module, which contains the oddly named hexlify function. Let's import it with from binascii import hexlify, and modify our diagnostic print statement to print hexlify buffer. This gives us a long hex string, which perhaps isn't even an improvement. What we really want to do is to split pairs of digits with white spaces. We can do this by slicing out consecutive pairs. In this code we hexlify, then decode to an ASCII string. We then join successive two digit slices with spaces using a range expression with a step of two. We then print the hex pairs. This is a big improvement, but it still leaves us counting bytes on the display. Let's precede our line of data with an integer count. Regenerate integers using a range, convert them to strings, and pad each number with leading 0s to a width of 2, good enough for the first 100 bytes of our data. Finally, we have something we can work with. It's slightly annoying that PyCharm interleaves output from the standard out and standard error streams in non-chronological order, but we can live with that for diagnostic code. Now we've got a useful way of viewing our bytes object. Let's get back to diagnosing our problem of why we have 80 bytes rather than 72. Looking carefully, we can see that the first bytes at indices 0 to 17 inclusive contain legitimate data, and we know this to be the case because we decoded it earlier. Looking at bytes 18 and 19, though, we see two 0 bytes. From bytes 20 to 37 inclusive we have another run of what looks like legitimate data, again, followed by another two 0 bytes at indices 38 and 39. This pattern continues to the end of the file. What we're seeing is padding added by the C compiler to align structures on 4 byte boundaries, and our 18 byte structure needs to be padded with 2 bytes to take it to 20 bytes, which is divisible by 4. In order to skip this padding we can use X, which is the format code for pad bytes. In this case, there are two pad bytes per structure, so we can add xx to our format string. With this change in place we can successfully read our structures from C into Python. You might be wondering why, given that we use the @ character at the beginning of our format string to specify native byte order, native size, and native alignment, this didn't work out of the box. So did we. Eventually we traced this mismatch to the fact that our Python interpreter, which is itself implemented in C, and our little C program for writing vertices to a file, were compiled using different C compilers with different structure-padding conventions. This just goes to show that when you're dealing with binary data you need to be very careful if you want your programs to be portable between systems and compilers.
